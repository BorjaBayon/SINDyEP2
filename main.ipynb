{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import numpy as np\n","import scipy as sp\n","import pandas as pd\n","import pysindy as ps\n","import matplotlib.pyplot as plt\n","import warnings\n","from imp import reload\n","\n","from utilities import *\n","from bootstrapping import *\n","from optimizers import *\n","from weak_forms import *"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def run_search(Theta, X_dot, var, \n","               n_bootstraps = 100, n_features_to_drop = 1, n_max_features = 5,\n","               feature_names_list = [\" \"], print_hierarchy = 0):\n","    \"\"\"\n","    Performs a searcg of the ALASSO solution (regularization) path, indentifies supports and fits them with OLS, returning the optimal model\n","    Can bootstrap data (n_bootstraps) and features (n_features_to_drop) randomly in the feature selection (support finding) process. \n","    Only keeps supports with a number of features below n_max_features \n","    IN: Theta [n_points, n_features], X_dot [n_points], supports [n_supports, n_features]\n","\n","    \"\"\"\n","    coefs = np.zeros((Theta.shape[1], 100, n_bootstraps))\n","    sup = np.zeros_like(coefs[:,:,0])\n","    supports = []\n","    with warnings.catch_warnings():\n","        warnings.filterwarnings(\"ignore\")\n","        for i in range(n_bootstraps):\n","            if n_bootstraps != 1:\n","                Theta_new, X_dot_new, inds = bootstrapping(Theta, X_dot, n_features_to_drop = n_features_to_drop)\n","            else:\n","                Theta_new, X_dot_new, inds = Theta, X_dot, np.arange(Theta.shape[1])\n","            alphas, coefs[inds, :, i] = ALASSO_path(Theta_new, X_dot_new[:,var].reshape(-1,1),)\n","            supports += identify_unique_supports(coefs[:,:,i], n_max_features = n_max_features)\n","            sup += np.abs(coefs[:,:,i]) > 0\n","        \n","    supports = remove_duplicates(supports)\n","    coef_list, score, n_terms = fit_supports(Theta, X_dot[:,var], supports)\n","    opt_coefs, index_min = find_optimal_support(coef_list, score, n_terms)\n","    print_hierarchy_f(print_hierarchy, coef_list, n_terms, score, feature_names_list)\n","    return opt_coefs, score[index_min]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 1. Test differential algorithm in Lotka-Volterra"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Denoised: Without ensembling\n","[1.00] x_dot = +   -10.00 x +    10.00 y \n","[1.00] y_dot = +    25.54 x +    -0.95 x z \n","[1.00] z_dot = +    -2.67 z +     1.00 x y \n","\n","5% Noise: Without ensembling\n","[-1.43] x_dot = +    -6.93 x +     8.86 y +    -0.06 x z \n","[-0.03] y_dot = +    25.16 x +    -0.94 x z \n","[0.27] z_dot = +    -2.63 z +     0.98 x y \n","\n","5% Noise: With ensembling\n","[-1.44] x_dot = +    -9.41 x +     9.50 y \n","[-0.03] y_dot = +    25.16 x +    -0.94 x z \n","[0.27] z_dot = +    -2.63 z +     0.98 x y \n"]}],"source":["def generate_Theta(X):\n","    Theta = np.vstack((np.ones_like(X[:,0]),\n","                    X[:,0], X[:,1], X[:,2], \n","                    X[:,0]*X[:,0], X[:,1]*X[:,1], X[:,1]*X[:,2],\n","                    X[:,0]*X[:,1], X[:,0]*X[:,2], X[:,1]*X[:,2])).T\n","    return Theta\n","\n","X, t = generate_data(10, 10/0.002, \"lorenz\")\n","X_dot = ps.SmoothedFiniteDifference()(X, t)\n","Theta = generate_Theta(X)\n","\n","feature_name_list = [\"1\", \"x\", \"y\", \"z\", \"x^2\", \"y^2\", \"z^2\", \"x y\", \"x z\", \"y z\"]\n","var_list = [\"x\", \"y\", \"z\"]\n","\n","opt_coefs = np.zeros((X.shape[1], Theta.shape[1]))\n","\n","print(\"Denoised: Without ensembling\")\n","for var in range(X.shape[1]):\n","    opt_coefs[var], score = run_search(Theta, X_dot, var,\n","                            n_bootstraps=1, n_features_to_drop=0,\n","                            feature_names_list=feature_name_list, print_hierarchy=0)\n","    print_model(opt_coefs[var], score, feature_name_list, var_list[var])\n","\n","###################\n","X = add_noise(X, 0.05)\n","X_dot = ps.SmoothedFiniteDifference()(X, t)\n","Theta = generate_Theta(X)\n","\n","print(\"\\n5% Noise: Without ensembling\")\n","for var in range(X.shape[1]):\n","    opt_coefs[var], score = run_search(Theta, X_dot, var,\n","                            n_bootstraps=1, n_features_to_drop=0,\n","                            feature_names_list=feature_name_list, print_hierarchy=0)\n","    print_model(opt_coefs[var], score, feature_name_list, var_list[var])\n","\n","print(\"\\n5% Noise: With ensembling\")\n","for var in range(X.shape[1]):\n","    opt_coefs[var], score = run_search(Theta, X_dot, var,\n","                            n_bootstraps=50, n_features_to_drop=1,\n","                            feature_names_list=feature_name_list, print_hierarchy=0)\n","    print_model(opt_coefs[var], score, feature_name_list, var_list[var])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 2. Test weak form algorithm in Lotka-Volterra"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Denoised: Weak without ensembling\n","[1.00] x_dot = +   -10.00 x +    10.00 y \n","[1.00] y_dot = +    24.73 x +    -0.92 x z \n","[1.00] z_dot = +    -2.67 z +     1.00 x y \n","\n","15% Noise: Weak without ensembling\n","[0.91] x_dot = +    -0.08 1 +   -10.15 x +     9.97 y \n","[0.94] y_dot = +    24.90 x +     0.00 z +    -0.92 x z \n","[0.93] z_dot = +     0.04 x +    -2.70 z +     1.03 x y \n","\n","15% Noise: Weak with ensembling\n","[0.91] x_dot = +   -10.44 x +    10.27 y \n","[0.94] y_dot = +    24.72 x +    -0.91 x z \n","[0.93] z_dot = +    -2.74 z +     1.04 x y \n"]}],"source":["X, t = generate_data(10, 10/0.002, \"lorenz\")\n","Theta = generate_Theta(X)\n","Theta_sm, X_sm = compute_weak_forms(Theta, X, t)\n","\n","feature_name_list = [\"1\", \"x\", \"y\", \"z\", \"x^2\", \"y^2\", \"z^2\", \"x y\", \"x z\", \"y z\"]\n","var_list = [\"x\", \"y\", \"z\"]\n","\n","opt_coefs = np.zeros((X.shape[1], Theta.shape[1]))\n","\n","print(\"Denoised: Weak without ensembling\")\n","for var in range(X.shape[1]):\n","    opt_coefs[var], score = run_search(Theta_sm, X_sm, var,\n","                            n_bootstraps=1, n_features_to_drop=0,\n","                            feature_names_list=feature_name_list, print_hierarchy=0)\n","    print_model(opt_coefs[var], score, feature_name_list, var_list[var])\n","\n","###################\n","X = add_noise(X, 0.15)\n","Theta = generate_Theta(X)\n","Theta_sm, X_sm = compute_weak_forms(Theta, X, t)\n","\n","print(\"\\n15% Noise: Weak without ensembling\")\n","for var in range(X.shape[1]):\n","    opt_coefs[var], score = run_search(Theta_sm, X_sm, var,\n","                            n_bootstraps=1, n_features_to_drop=0,\n","                            feature_names_list=feature_name_list, print_hierarchy=0)\n","    print_model(opt_coefs[var], score, feature_name_list, var_list[var])\n","\n","print(\"\\n15% Noise: Weak with ensembling\")\n","for var in range(X.shape[1]):\n","    opt_coefs[var], score = run_search(Theta_sm, X_sm, var,\n","                            n_bootstraps=50, n_features_to_drop=1,\n","                            feature_names_list=feature_name_list, print_hierarchy=0)\n","    print_model(opt_coefs[var], score, feature_name_list, var_list[var])"]}],"metadata":{"kernelspec":{"display_name":"pysindy-development","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
