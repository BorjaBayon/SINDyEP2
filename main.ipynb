{"cells":[{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["import numpy as np\n","import scipy as sp\n","import pandas as pd\n","import pysindy as ps\n","import matplotlib.pyplot as plt\n","import warnings\n","\n","from utilities import *\n","from bootstrapping import *\n","from optimizers import *\n","from weak_forms import *"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def run_search(Theta, X_dot, var, \n","               n_bootstraps = 100, n_features_to_drop = 1, n_max_features = 5,\n","               feature_names_list = [\" \"], print_hierarchy = 0):\n","    \"\"\"\n","    Performs a searcg of the ALASSO solution (regularization) path, indentifies supports and fits them with OLS, returning the optimal model\n","    Can bootstrap data (n_bootstraps) and features (n_features_to_drop) randomly in the feature selection (support finding) process. \n","    Only keeps supports with a number of features below n_max_features \n","    IN: Theta [n_points, n_features], X_dot [n_points], supports [n_supports, n_features]\n","\n","    \"\"\"\n","    coefs = np.zeros((Theta.shape[1], 100, n_bootstraps))\n","    sup = np.zeros_like(coefs[:,:,0])\n","    supports = []\n","    with warnings.catch_warnings():\n","        warnings.filterwarnings(\"ignore\")\n","        for i in range(n_bootstraps):\n","            if n_bootstraps != 1:\n","                Theta_new, X_dot_new, inds = bootstrapping(Theta, X_dot, n_features_to_drop = n_features_to_drop)\n","            else:\n","                Theta_new, X_dot_new, inds = Theta, X_dot, np.arange(Theta.shape[1])\n","            alphas, coefs[inds, :, i] = ALASSO_path(Theta_new, X_dot_new[:,var].reshape(-1,1),)\n","            supports += identify_unique_supports(coefs[:,:,i], n_max_features = n_max_features)\n","            sup += np.abs(coefs[:,:,i]) > 0\n","        \n","    supports = remove_duplicates(supports)\n","    coef_list, score, n_terms = fit_supports(Theta, X_dot[:,var], supports)\n","    opt_coefs, index_min = find_optimal_support(coef_list, score, n_terms)\n","    print_hierarchy_f(print_hierarchy, coef_list, n_terms, score, feature_names_list)\n","    return opt_coefs, score[index_min]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X, t = generate_data(10, 10/0.02, \"lorenz\")\n","X = add_noise(X, 0.05)\n","X_dot = ps.SmoothedFiniteDifference()(X, t)\n","\n","Theta = np.vstack((np.ones_like(X[:,0]),\n","                X[:,0], X[:,1], X[:,2], \n","                X[:,0]*X[:,0], X[:,1]*X[:,1], X[:,1]*X[:,2],\n","                X[:,0]*X[:,1], X[:,0]*X[:,2], X[:,1]*X[:,2])).T\n","feature_name_list = [\"1\", \"x\", \"y\", \"z\", \"x^2\", \"y^2\", \"z^2\", \"x y\", \"x z\", \"y z\"]\n","\n","opt_coefs = np.zeros((X.shape[1], Theta.shape[1]))\n","\n","for var in range(X.shape[1]):\n","    opt_coefs[var], score = run_search(Theta, X_dot, var,\n","                            n_bootstraps=1, n_features_to_drop=0,\n","                            feature_names_list=feature_name_list, print_hierarchy=0)\n","    \n"]}],"metadata":{"kernelspec":{"display_name":"pysindy-development","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
